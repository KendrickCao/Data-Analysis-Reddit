{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: KNOWLEDGE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = 'data_reddit.csv'\n",
    "df_reddit = pd.read_csv(data_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I. Import the .csv data into a dataframe `covid_subreddits` with the following columns: `author`, `posted_at`, `num_comments`, `score`, `selftext`, `subbredit`, `title`. Remove any data that is not part of the following subreddits: Coronavirus, CoronavirusUK, CoronavirusUS, COVID, COVID19.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61539</td>\n",
       "      <td>2020-03-11 07:36:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Coronavirus updates: CDC says people who test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61539</td>\n",
       "      <td>2020-07-26 14:42:00</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>You're going to need more than one coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>61539</td>\n",
       "      <td>2020-12-11 17:55:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Congressional COVID-19 imp[***]e continues, Pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>61539</td>\n",
       "      <td>2020-07-27 14:13:00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>First Phase 3 test of coronavirus vaccine cand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>61539</td>\n",
       "      <td>2020-07-29 08:55:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>'The hotspot of a hotspot of a hotspot': coron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>Zuom</td>\n",
       "      <td>2020-03-15 21:05:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Fresno County declared a state of emergency Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>Zuom</td>\n",
       "      <td>2020-03-25 15:55:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Dad in China designs ‘safety pod’ to protect b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18342</th>\n",
       "      <td>Zuom</td>\n",
       "      <td>2020-04-04 03:12:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Rick Perry asks for elastic donations for his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18343</th>\n",
       "      <td>Zuom</td>\n",
       "      <td>2020-02-04 07:34:00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>NYC homeless services worker[***] with coronav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18344</th>\n",
       "      <td>Zuom</td>\n",
       "      <td>2020-03-19 02:58:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>Hospital workers battling the coronavirus in W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3705 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      author           posted_at  num_comments  score selftext    subreddit  \\\n",
       "9      61539 2020-03-11 07:36:00           8.0    1.0      NaN  Coronavirus   \n",
       "10     61539 2020-07-26 14:42:00         116.0    1.0      NaN  Coronavirus   \n",
       "11     61539 2020-12-11 17:55:00           1.0    1.0      NaN  Coronavirus   \n",
       "12     61539 2020-07-27 14:13:00          13.0    1.0      NaN  Coronavirus   \n",
       "13     61539 2020-07-29 08:55:00           6.0    1.0      NaN  Coronavirus   \n",
       "...      ...                 ...           ...    ...      ...          ...   \n",
       "18340   Zuom 2020-03-15 21:05:00           5.0    1.0      NaN  Coronavirus   \n",
       "18341   Zuom 2020-03-25 15:55:00          20.0    1.0      NaN  Coronavirus   \n",
       "18342   Zuom 2020-04-04 03:12:00           5.0    1.0      NaN  Coronavirus   \n",
       "18343   Zuom 2020-02-04 07:34:00           4.0    1.0      NaN  Coronavirus   \n",
       "18344   Zuom 2020-03-19 02:58:00          34.0   42.0      NaN  Coronavirus   \n",
       "\n",
       "                                                   title  \n",
       "9      Coronavirus updates: CDC says people who test ...  \n",
       "10     You're going to need more than one coronavirus...  \n",
       "11     Congressional COVID-19 imp[***]e continues, Pe...  \n",
       "12     First Phase 3 test of coronavirus vaccine cand...  \n",
       "13     'The hotspot of a hotspot of a hotspot': coron...  \n",
       "...                                                  ...  \n",
       "18340  Fresno County declared a state of emergency Su...  \n",
       "18341  Dad in China designs ‘safety pod’ to protect b...  \n",
       "18342  Rick Perry asks for elastic donations for his ...  \n",
       "18343  NYC homeless services worker[***] with coronav...  \n",
       "18344  Hospital workers battling the coronavirus in W...  \n",
       "\n",
       "[3705 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning data\n",
    "df_tmp=df_reddit[['user_registered_at','user_upvote_ratio']].dropna()   # get the last two colums\n",
    "df_reddit.drop(labels=['user_registered_at','user_upvote_ratio'],axis=1,inplace=True)   # remove last two colums\n",
    "df_reddit.dropna(thresh=5,inplace=True)    # delete row if less than 5 non-empty value in this row.\n",
    "df_reddit.reset_index(drop=True, inplace=True)  # reset the index after droping many rows\n",
    "df_reddit=pd.concat([df_reddit,df_tmp],axis=1)  # splice two dataframe \n",
    "df_reddit['posted_at']=pd.to_datetime(df_reddit['posted_at'])  # convert post at to datetime \n",
    "# df_reddit['selftext'].fillna('',inplace=True) # fill NaN with blank string\n",
    "# df_reddit.fillna(0.0,inplace=True) # fill na with 0.0 such as time and ratio\n",
    "covid_subreddits=df_reddit[['author','posted_at','num_comments','score','selftext','subreddit','title']]\n",
    "covid_subreddits=covid_subreddits[covid_subreddits['subreddit'].isin(['Coronavirus','CoronavirusUK','CoronavirusUS','COVID','COVID19'])]\n",
    "\n",
    "covid_subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II.Create a new dataframe: [5 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Make a new dataframe `subreddit_overview` with columns `subreddit` and `nbr_of_posts`, that counts how many posts have been made in each subreddit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>nbr_of_posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>3078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoronavirusUK</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CoronavirusUS</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subreddit  nbr_of_posts\n",
       "0          COVID            50\n",
       "1        COVID19           200\n",
       "2    Coronavirus          3078\n",
       "3  CoronavirusUK           215\n",
       "4  CoronavirusUS           162"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_overview = covid_subreddits[['subreddit','title']]\n",
    "subreddit_overview = subreddit_overview.groupby(['subreddit']).size().reset_index() \n",
    "subreddit_overview.rename(columns={0:'nbr_of_posts'},inplace=True)\n",
    "\n",
    "subreddit_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Add a column `avg_title_length` to the `subreddit_overview` dataframe averaging the post `title` length for each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_tmp=covid_subreddits.loc[:,['title','subreddit']]  # create a temp dataframe for caculating\n",
    "b_tmp['title_length']=b_tmp['title'].str.len()\n",
    "\n",
    "# aggregation\n",
    "b_tmp=b_tmp.groupby(['subreddit'])\n",
    "b_tmp=b_tmp['title_length'].mean().reset_index()\n",
    "subreddit_overview['avg_title_length'] = b_tmp['title_length']  # add avg_title_length column to final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Add a column `comment_text_ratio` to the `subreddit_overview` dataframe calculating the ratio between the length of the `selftext` and the number of comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tmp=covid_subreddits.loc[:,['subreddit','selftext','num_comments']]\n",
    "\n",
    "c_tmp['comment_text_ratio']=c_tmp['selftext'].str.len()/c_tmp['num_comments']\n",
    "c_tmp.drop(columns='selftext',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Print the subreddit_overview dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>comment_text_ratio</th>\n",
       "      <th>nbr_of_posts</th>\n",
       "      <th>avg_title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3078</td>\n",
       "      <td>84.067901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3078</td>\n",
       "      <td>84.067901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3078</td>\n",
       "      <td>84.067901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3078</td>\n",
       "      <td>84.067901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3078</td>\n",
       "      <td>84.067901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3700</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3703</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>COVID19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3705 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit  num_comments  comment_text_ratio  nbr_of_posts  \\\n",
       "0     Coronavirus           8.0                 NaN          3078   \n",
       "1     Coronavirus         116.0                 NaN          3078   \n",
       "2     Coronavirus           1.0                 NaN          3078   \n",
       "3     Coronavirus          13.0                 NaN          3078   \n",
       "4     Coronavirus           6.0                 NaN          3078   \n",
       "...           ...           ...                 ...           ...   \n",
       "3700      COVID19          23.0                 NaN           200   \n",
       "3701      COVID19          33.0                 NaN           200   \n",
       "3702      COVID19           0.0                 NaN           200   \n",
       "3703      COVID19          14.0                 NaN           200   \n",
       "3704      COVID19           5.0                 NaN           200   \n",
       "\n",
       "      avg_title_length  \n",
       "0            84.067901  \n",
       "1            84.067901  \n",
       "2            84.067901  \n",
       "3            84.067901  \n",
       "4            84.067901  \n",
       "...                ...  \n",
       "3700         91.500000  \n",
       "3701         91.500000  \n",
       "3702         91.500000  \n",
       "3703         91.500000  \n",
       "3704         91.500000  \n",
       "\n",
       "[3705 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddit_overview=pd.merge(c_tmp,subreddit_overview,how='inner',on='subreddit')\n",
    "subreddit_overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III. Perform sentiment analysis on the `selftext` of the `covid_subreddits` dataframe. Calculate and print: the average sentiment per subreddit, the subreddits that are positive overall (if any), and the subreddits that are negative overall (if any). Print the resulting dataframes to .csv files named respectively `sa_results.csv`, `positive_subs.csv`, and `negative_subs.csv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eng_spacysentiment\n",
    "import spacy\n",
    "nlp_s = eng_spacysentiment.load() # load in the sentiment model with default parameters\n",
    "nlp_m = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment=covid_subreddits.dropna(subset='selftext').loc[:,['subreddit','selftext']] # remove rows if selftext=NaN \n",
    "sentiment[['positive','negative']]=''   # insert two blank rows\n",
    "for i in range(len(sentiment)):\n",
    "    positive=0;negative=0\n",
    "    doc=nlp_m(sentiment['selftext'].values[i])  # get cell value in selftext columns\n",
    "    numOfSents = len(list(doc.sents))\n",
    "    for sent in doc.sents:  # loop in one cell\n",
    "        doc = nlp_s(str(sent))\n",
    "        positive = positive + doc.cats[\"positive\"]  # sum sentiment value of each sentence\n",
    "        negative = negative + doc.cats[\"negative\"]\n",
    "    # cell sentiment equals sum sentiment divides number of sentence\n",
    "    sentiment['positive'].values[i] = positive/numOfSents\n",
    "    sentiment['negative'].values[i] = negative/numOfSents\n",
    "# caculate overall sub sentiment\n",
    "sa_results=sentiment.groupby(['subreddit'])\n",
    "sa_results=sa_results[['positive','negative']].mean().reset_index()\n",
    "postive_subs=sa_results.loc[sa_results['positive']>sa_results['negative'],'subreddit']\n",
    "negative_subs=sa_results.loc[sa_results['positive']<sa_results['negative'],'subreddit']\n",
    "# export csv\n",
    "postive_subs.to_csv(\"postive_subs.csv\")\n",
    "negative_subs.to_csv(\"negative_subs.csv\")\n",
    "sa_results.to_csv(\"sa_results.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV. Find the top 2 posters in the CoronavirusUK subreddit and calculate and print the similarity between the titles of all posts by each user. Return only one value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462759212218078"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_posters=covid_subreddits.loc[:,['author','subreddit']]\n",
    "top_posters=top_posters[top_posters['subreddit'].isin(['CoronavirusUK'])]   # get column subreddit=CoronavirusUK\n",
    "# count how many times the author posts in\n",
    "top_posters=top_posters.groupby(['author']).count().reset_index().sort_values('subreddit').tail(2)\n",
    "top_posters=pd.merge(covid_subreddits,top_posters,how='inner',on='author') # merge it to origin df to sum title\n",
    "top_posters=top_posters.groupby(['author'])\n",
    "top_posters=top_posters['title'].sum().reset_index()\n",
    "\n",
    "poster1=nlp_m(top_posters['title'].values[0])\n",
    "poster2=nlp_m(top_posters['title'].values[1])\n",
    "\n",
    "poster1.similarity(poster2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V. Extract the Named Entities/Keywords of the CoronavirusUK using an appropriate Python library for each of the following months: January 2020, May 2020, September 2020. Print which Named Entities/keywords appear in all 3 three months (if any) and which only appear in each month exclusively (if any).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('England', 'GPE'), ('UK', 'GPE')} \n",
      "\n",
      " {('early years', 'DATE'), ('first', 'ORDINAL'), ('ZOE Update', 'PERSON'), ('November 1st 2020', 'DATE'), ('three', 'CARDINAL'), ('Tuesday 01 December', 'DATE'), ('Tony Jones', 'PERSON'), ('Ronald McDonald', 'PERSON'), ('Week 43 2020', 'DATE')} \n",
      "\n",
      " {('1st 2', 'DATE'), ('Govt', 'ORG'), ('Vent Megathread - May', 'PRODUCT'), ('Today', 'DATE'), ('June 15', 'DATE'), ('Peter Hitchens', 'PERSON'), ('29', 'CARDINAL'), ('Oxfordshire', 'GPE'), ('Europe', 'LOC'), ('Denmark', 'GPE'), ('U.K.', 'GPE'), ('May 26th 2020', 'DATE'), ('Cummings', 'GPE'), ('Greece', 'GPE'), ('China', 'GPE'), ('29,427', 'CARDINAL')} \n",
      "\n",
      " {('10 days', 'DATE'), ('Vent Megathread - September', 'PRODUCT'), ('Norwegian', 'NORP'), ('Covid-19 Deaths', 'PERSON'), ('more than a year', 'DATE'), ('only 3%', 'PERCENT'), ('Brexit', 'PERSON'), ('Britons', 'PERSON'), ('an Office for National Statistics', 'ORG'), ('six', 'CARDINAL'), ('two weeks', 'DATE'), ('Friday 09 October', 'DATE'), ('July 9th 2020', 'DATE'), ('Coronavirus', 'ORG'), ('winter', 'DATE'), ('Britain', 'GPE'), ('COVID-19) Infection Survey', 'ORG'), ('Red Line', 'ORG'), ('Guardian', 'ORG'), ('tomorrow', 'DATE'), ('CQC', 'ORG'), ('Amazon', 'ORG'), ('10pm', 'TIME'), ('1.1-1.4', 'CARDINAL'), ('29th May 2020', 'DATE'), ('the Scottish Government', 'ORG'), ('October', 'DATE'), ('Age Group - w/e', 'ORG'), ('COVID-19', 'PERSON'), ('Chinese', 'NORP'), ('1.2-1.5', 'CARDINAL'), ('9th', 'ORDINAL')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c21106784\\AppData\\Local\\Temp\\ipykernel_20324\\1855800624.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  entities[\"tokens\"]=entities[\"title\"].apply(nlp_m)\n"
     ]
    }
   ],
   "source": [
    "entities=covid_subreddits[covid_subreddits['subreddit'].isin(['CoronavirusUK'])]\n",
    "entities[\"tokens\"]=entities[\"title\"].apply(nlp_m)\n",
    "jan_entities=entities.loc[entities['posted_at'].between('2020-01-01','2020-01-31')]\n",
    "may_entities=entities.loc[entities['posted_at'].between('2020-05-01','2020-05-31')]\n",
    "sep_entities=entities.loc[entities['posted_at'].between('2020-09-01','2020-09-30')]\n",
    "jan_list=[];may_list=[];sep_list=[]\n",
    "for tokens in jan_entities['tokens'].values:\n",
    "    for ent in tokens.ents:\n",
    "        jan_list.append((ent.text,ent.label_))\n",
    "for tokens in may_entities['tokens'].values:\n",
    "    for ent in tokens.ents:\n",
    "        may_list.append((ent.text,ent.label_))\n",
    "for tokens in sep_entities['tokens'].values:\n",
    "    for ent in tokens.ents:\n",
    "        sep_list.append((ent.text,ent.label_))\n",
    "\n",
    "all_three = set(jan_list).intersection(may_list,sep_list)\n",
    "only_jan = set(jan_list).difference(may_list,sep_list)\n",
    "only_may = set(may_list).difference(jan_list,sep_list)\n",
    "only_sep = set(sep_list).difference(may_list,jan_list)\n",
    "print(all_three,'\\n\\n',only_jan,'\\n\\n',only_may,'\\n\\n',only_sep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
